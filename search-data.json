[
    
    
    
        
            {
                "id": 0,
                "href": "http://kihlander.net/post/when-memcpy-change/",
                "title": "When memcpy() change!",
                "section": "post",
                "date" : "2022.10.23",
                "body": " To start of, yes, I know that this article touch undefined behavior and that all bets are off!\nI am currently working on a bigger post on swapping memory that is THIS close to being done\u0026hellip; any day now (he has been saying the last year!).\nHowever this topic popped up and I was wondering if it was worth making the other post longer or just make a small one about it. As the other post is already quite big I opted for a shorter one here.\nSo what am I on about you might ask, weird title and all? memcpy() don\u0026rsquo;t just change right, it is well defined what it should do! It should copy memory from buffer a to buffer b\u0026hellip; as long as they don\u0026rsquo;t overlap, then your in undefined behavior territory (spooky sounds go here!).\nIn c and c++ we basically have 2 primitives to copy memory, we have memcpy() and memmove() where memcpy() is \u0026ldquo;as efficient as possible\u0026rdquo; and memmove() also handle the case where source and destination overlap and copy the data as if a temporary buffer was used in between.\nSo far so good, i.e. you, as a user of the functions, is expected to know if you have overlapping buffers in your src and dst.\nWell as it turns out, you and me as developers are quite bad att knowing if your buffers DO overlap or not, as seen by the kerfuffle back in 2010 when GLIBC decided to replace its old memcpy() that just used memmove() with an optimized version that really required the buffers not to overlap. \u0026ldquo;Hilarity\u0026rdquo; ensued and everyone had a great day at work\u0026hellip; or maybe I misunderstood something? ;)\nIMHO it is the right decision on a system-level to implement memcpy() as memmove() for the above mentioned reason, that reason being you and me as developers are stupid :) Many systems however don\u0026rsquo;t do this so we still need to think about it.\nAnd now to the interesting part\u0026hellip; lets try this out on my linux-machine. Let us add a simple program like this:\nIn this post I will define \u0026ldquo;the right\u0026rdquo; behavior to be memmove() all the time\u0026hellip; if this is right can absolutely be debated and I would not be on the side that it is ALWAYS the right choice, but for the sake of this article we define that as \u0026ldquo;right\u0026rdquo;.\nTrying it out #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(int, const char**) { int cpy[] {0, 1, 2, 3, 4, 5, 6}; int mov[] {0, 1, 2, 3, 4, 5, 6}; memcpy (\u0026amp;cpy[1], \u0026amp;cpy[0], 5 * sizeof(int)); // OHNO... overlap ahoy! memmove(\u0026amp;mov[1], \u0026amp;mov[0], 5 * sizeof(int)); printf(\u0026#34;cpy: \u0026#34;); for(int c : cpy) printf(\u0026#34;%d \u0026#34;, c); printf(\u0026#34;\\n\u0026#34;); printf(\u0026#34;mov: \u0026#34;); for(int c : mov) printf(\u0026#34;%d \u0026#34;, c); printf(\u0026#34;\\n\u0026#34;); return 0; } play along in compiler explorer\nCompile with gcc\u0026hellip;\nwc-duck@WcLaptop:~/kod$ gcc test.cpp -o t wc-duck@WcLaptop:~/kod$ ./t cpy: 0 0 1 2 3 4 6 mov: 0 0 1 2 3 4 6 \u0026hellip; and success!\n\u0026hellip; and clang? \u0026hellip;\nwc-duck@WcLaptop:~/kod$ clang test.cpp -o t wc-duck@WcLaptop:~/kod$ ./t cpy: 0 0 1 1 3 3 6 mov: 0 0 1 2 3 4 6 OH NO!\nIf we dig in to the code that clang generates we see that clang has replaced the call to memcpy() and memmove() with its own inline implementations that DO follow the rules and expect input to memcpy() to not overlap. A valid conversion as it seems really wasteful to copy a few bytes via a function-call. (Question however, is clang really allowed to do this in a non-optimized build?)\nWe can also try an optimized build.\nwc-duck@WcLaptop:~/kod$ gcc test.cpp -o t -O2 wc-duck@WcLaptop:~/kod$ ./t cpy: 0 0 1 2 3 3 6 mov: 0 0 1 2 3 4 6 wc-duck@WcLaptop:~/kod$ clang test.cpp -o t -O2 wc-duck@WcLaptop:~/kod$ ./t cpy: 0 0 1 2 3 4 6 mov: 0 0 1 2 3 4 6 Now we see that gcc generate an invalid(?) result but clang generate what would be expected(?). This time gcc decided to replace memcpy() with an inlined version that is a \u0026ldquo;pure\u0026rdquo; memcpy(). But how did clang get it \u0026ldquo;right\u0026rdquo;, lets dig in?\nIt seem like the diff on clang between -O0 and -O2 is that it uses vector-instructions to implement its inlined memcpy() and memmove() and unroll the loop here as there are no branch-instructions in the copies that should occur\u0026hellip; I\u0026rsquo;m not really sure what is going on here, but we can at least conclude that in this case clang generate different code that result in different semantics depending on optimization flags. I guess we are in undefined behavior land now ¯\\(ツ)/¯\nConclusions? So what have we learned? Don\u0026rsquo;t know really\u0026hellip; undefined behavior is undefined maybe?\nOn a more serious note, should we be able to expect our compilers to generate equivalent code depending optimization level? One might think so but I guess that would have a lot of repercussions in other areas.\nAnd in cases like this where the compiler could easily see that the buffers overlap, should they generate memmove()-semantics code here? I know that some static-analyzers warn about this, but for all old code, why not try to at least save them from them self (and emit a warning)? I would be surprised to find code where the undefined behavior of memcpy() would be what you actually wanted?\nRegardless, I found this little \u0026ldquo;thing\u0026rdquo; was worth a few words in blog-form just for the sake of it\u0026hellip; hope you found it at least worth your time reading it :)\n"
            }
    
        ,
            {
                "id": 1,
                "href": "http://kihlander.net/post/macros-and-lambdas/",
                "title": "Macros and Lambdas",
                "section": "post",
                "date" : "2022.10.16",
                "body": "Time for a short post on using lambdas to construct macros\u0026hellip; that was a sentence that will be able to trigger 2 camps in one go :D\nDefer First of, using lambdas to implement a defer() is really neat, however others has already written about that so that I don\u0026rsquo;t have to!\nA Defer Statement For C++11\nCall once So from my end I\u0026rsquo;ll start of with a quick one for constructing a macro that only does something once, lets call it IS_FIRST_CALL(). This can be used for things such as only logging something once or just asserting once. I\u0026rsquo;ll leave it to the reader to decide if this is a \u0026ldquo;good\u0026rdquo; thing but it is absolutely things I have seen \u0026ldquo;in the wild\u0026rdquo;.\n// ... it can be used to implement other macros ... #define PRINT_ONCE(s, i) \\ do { \\ if(IS_FIRST_CALL()) \\ printf(s \u0026#34; %d\\n\u0026#34;, i); \\ } while(false) int a_function(int i) { if(i \u0026gt; 43) PRINT_ONCE(\u0026#34;first time i was bigger than 43 it was %d\u0026#34;, i); // ... or by itself ... if(i \u0026lt; 43 \u0026amp;\u0026amp; IS_FIRST_CALL()) printf(\u0026#34;first time i was smaller than 43 it was %d\u0026#34;, i); } A implementation of this would be something like this:\n#define JOIN_2(x, y) x##y #define JOIN_1(x, y) JOIN_2(x, y) #define JOIN(x, y) JOIN_1(x, y) #define IS_FIRST_CALL() \\ [](){ \\ static bool JOIN(call_it, __LINE__) = true; \\ bool JOIN(call, __LINE__) = JOIN(call_it, __LINE__); \\ JOIN(call_it, __LINE__) = false; \\ return JOIN(call, __LINE__); \\ }() We use a lambda (i.e. introduce a local function) to enable us to declare and check a static variable in any scope and \u0026ldquo;join\u0026rdquo; in the line-number to make sure that we don\u0026rsquo;t get warnings for variable \u0026ldquo;shadowing\u0026rdquo;.\nNot much code, but increasing readability according to me!\nSilence unused variables Next one!\nIn the codebase\u0026rsquo;s where I usually work we treat unused variables as errors (for better or for worse!), imho this is usually valuable as it help with getting rid of dead code. However it do introduce issues with things such as logging and asserts where variables and functions only become unused in specific configs.\nConsider something like this, where we have a PRINT() function that can be disabled with a define.\n#if !defined(SHOULD_PRINT) #define PRINT(fmt, ...) // NOTHING! #else #define PRINT(fmt, ...) printf(fmt, __VA_ARGS__) #endif int main(int, char**) { int var = 0; PRINT(\u0026#34;an int %d\u0026#34;, var); return 0; } Compiling and running this works just fine \u0026hellip;\nwc-duck@WcLaptop:~/kod$ clang++ t.cpp -Wall wc-duck@WcLaptop:~/kod$ ./a.out an int 1337 \u0026hellip; until someone disables the printing!\nwc-duck@WcLaptop:~/kod$ clang++ t.cpp -Wall -DNO_PRINT t.cpp:63:9: warning: unused variable \u0026#39;var\u0026#39; [-Wunused-variable] int var = 1337; ^ 1 warning generated. Time to introduce SILENCE_UNUSED(...)\n#define SILENCE_UNUSED(...) \\ do { \\ if(false) \\ [](...){} (__VA_ARGS__); \\ } while(false) This can then be used to implement PRINT() or by itself!\n#if !defined(SHOULD_PRINT) #define PRINT(fmt, ...) SILENCE_UNUSED(__VA_ARGS__) #else #define PRINT(fmt, ...) printf(fmt, __VA_ARGS__) #endif There are however quite a bit to unpack here, why is all the different parts needed.\nFirst, we define a lambda taking variadic arguments, thus being able to use the argument without giving them a name\u0026hellip; it turns out compilers have a hard time reporting warnings for variables they can\u0026rsquo;t be sure that they exist ;) This could of course also be possible with a [[maybe_unused]] void silence_me(...) {} but I prefer a lambda here to not \u0026ldquo;pollute\u0026rdquo; the global namespace with an implementation detail.\nSecondly we need to put the call to the lambda within an if(false) to make sure that the actual arguments isn\u0026rsquo;t evaluated. We wouldn\u0026rsquo;t want a SILENCE_UNUSED(expensive_call()) to actually call expensive_call() do we!\nLastly we wrap all of it in the mandatory do {} while(false) to make the macro into a \u0026ldquo;proper\u0026rdquo; statement that is useable within if/else etc.\nConclusion So\u0026hellip; there we have it, some simple tools to build your macros using lambdas! Personally I find them kind of neat and I think they server a purpose!\n"
            }
    
        ,
            {
                "id": 2,
                "href": "http://kihlander.net/post/when-selecting-a-theme-is-your-biggest-problem/",
                "title": "When selecting a theme is your biggest problem!",
                "section": "post",
                "date" : "2022.07.23",
                "body": "I have been using pellican to generate and maintain my blog sinces its inception and it has been mainly fine. However after getting a new machine and starting to fiddle with a new post I started noticing things such as installation being far from optimal and it no longer generating a functioning site after updating pellican.\nAfter an update all line-breaks in code-segments just got removed, did I configure something wrong, what to do to fix it? Don\u0026rsquo;t know and Im not really keen on finding out.\nThis looked like a perfect time to try out something new and since hugo seems to be the \u0026ldquo;hottest thing around\u0026rdquo; I went for that\u0026hellip;\nAnd such a treat it was! As the title states, the hardest thing of this migration was to actually select a theme I liked (ended up with harbor by Masaya Watanabe as you might see :))! Everything else was just a smooth. Things such as:\nFrom having a single binary to \u0026ldquo;install\u0026rdquo; Really simple setup Great get started-doc Smooth builtin server with auto-update on content updates. Being markdown-based, making it trivial to switch from pellican. Simply a treat to work with!\nDon\u0026rsquo;t think I have anything else to add and I hope to be able to roll out some more \u0026ldquo;meaty\u0026rdquo; posts in the future. I have one in the making that has been sitting, waiting to be completed, since christmas that I hope to publish soon.\n"
            }
    
        ,
            {
                "id": 3,
                "href": "http://kihlander.net/about/",
                "title": "About",
                "section": "",
                "date" : "2022.07.19",
                "body": "Who I am I\u0026rsquo;m Fredrik Kihlander, engine programmer at Avalanche Studios by day, father and avid amateur cook at night.\nThe goal of this blog is to have somewhere to write down code-related things that might be of interest to others. Mainly C++ ( with a really light emphasis on the ++:es ), maybe some python and general game-dev stuff.\nDon\u0026rsquo;t expect regular updates!\n"
            }
    
        ,
            {
                "id": 4,
                "href": "http://kihlander.net/post/protothreads-with-a-twist/",
                "title": "\"ProtoThreads\" with a twist.",
                "section": "post",
                "date" : "2018.11.20",
                "body": "For a long time I\u0026rsquo;v been interested in running game-specific/entity-specific code in coroutines. Something like the following.\nvoid some_game_object_behavior( entity ent, ... ) { pnt3 points[] = { {1,1,1}, {2,2,2}, {3,3,3}, {4,4,4} }; int pos = 0; while(entity_alive(ent)) { // move the entity to a position and yield coroutine while movement is ongoing. move_to(ent, points[pos % ARRAY_LENGTH(points)]); pos++; for(int i = 0; i \u0026lt; 4; ++i) { shoot_bullet(ent); wait_sec(ent, 2); // do nothing for 2 seconds and yield the coroutine for that duration. } } } The above example is slightly simplified but I hope that it get the point across, that I want to be able to suspend code-execution at specific points and wait for certain actions to complete. Writing one-off game-code in this fashion might be a good way to work, especially when adding wait_for_any() and wait_for_all() etc.\nSo when I finally decided to take a stab at trying that out I started out by looking at how to implement the actual coroutines. There are a couple of libraries out there that I looked at for coroutines in c/c++ such as:\nlibaco libdill libmill Both libdill and libmill feel too \u0026lsquo;opinionated\u0026rsquo; on how they want you to structure your code ( not that weird since the both sets out to re-implement go:s goroutines in c ) and also feels \u0026lsquo;heavier\u0026rsquo; than what I need. libaco however sparked my interest, it looked quite lean and not too opinionated, i.e. it looks really nice! But there is a big BUT, no windows support yet =/ I do most of my development on Linux but throwing Windows support out of the \u0026ldquo;window\u0026rdquo; (badumtish) is not something I want to do. According to the issue-tracker it is in \u0026ldquo;the pipe\u0026rdquo; but it is not supported as of writing this.\nThis lead me to fire of a question on twitter about alternatives and where @RandyPGaul pointed out something that I had looked at before but totally forgot about, coroutines/protothreads based on \u0026ldquo;duff\u0026rsquo;s device\u0026rdquo;.\nSince this technique is already well documented on the interwebs I\u0026rsquo;ll just link to the original article here and wait until you have read it ( if you haven\u0026rsquo;t already ).\ncoroutines in c\nRead it yet? Good!\nHere are a few other links to libs that implement these kind of coroutines.\nprotothreads zserge/pt cute_coroutine What I like about this solution is that it is \u0026ldquo;just code\u0026rdquo; so it should in theory work on any platform without platform-specific code. It should also work with emscripten ( that I shall get running any day now!!! ;) ).\nThere are however things that I am missing from these otherwise fine libraries. A major one is based in how I plan to use them. I plan to have all my \u0026ldquo;behaviors\u0026rdquo; run one coroutine and have some kind of simple \u0026ldquo;scheduler\u0026rdquo; run them. Something simple as having all \u0026ldquo;active\u0026rdquo; coroutines in a list, remove them from the list when waiting for something, and update them in a loop. However doing that with the above libs would require me keeping track of what functions are associated with each coroutine state.\nAlso local variables/state is not handled by the above libs and would need to be handled by passing in some kind of state-struct, that would need to be different for each \u0026ldquo;behavior\u0026rdquo; and also be tracked by the above mentioned system.\n2 of the 3 libs also fails to handle calling another coroutine-function from within a coroutine and by that having the sub-call control the state of the top-level coroutine. For example if a sub-call does a yield or wait the entire call-hierarchy should do the same (cute_coroutine.h solves this for a fixed depth of sub-calls).\nSo what do you do when you have an interesting itch to scratch? You scratch it of course :)\nSolving the issues! As any decent NIH-addict I decided to try myself and see what I could do and came to the conclusion that all the above issues can be solved by adding a small stack to each coroutine, i.e. almost do what the compiler does!\nIntroducing my boringly named coroutine lib/header, coro.\nAs mentioned above the only real difference between coro and the above mentioned libs are that each coroutine in coro MAY have a stack associated with it where the system itself can push data and reset when a coroutine completes.\nWarning for you C-all-the-way people, there be some usage of C++ in this piece of code! But I guess it wouldn\u0026rsquo;t be that hard to C:ify the lib if there is demand for it!\nThe library does nothing particularly fancy at its core, the simplest coroutine would be implemented and updated like this.\nvoid my_coro( coro* co, void*, void* ) { // all coroutines need a matching co_begin/co_end-pair co_begin(co); // ... do stuff ... // ... yield execution of coroutine, i.e. introduce a yield-point in the // function where to continue execution on the next update ... co_yield(co); co_end(co); } void run_it() { // ... create and initialize our coroutine ... coro co; co_init(\u0026amp;co, nullptr, 0, my_coro); // ... resume until completed ... while(!co_completed(\u0026amp;co)) co_resume(\u0026amp;co); } But now to the meat of this post, how will adding a stack solve the above mentioned issues?\nGeneral coroutine update Well, this isn\u0026rsquo;t solved by the stack, this is just solved by introducing a struct for the coroutines and storing a function-ptr in it :) Now we have that out of the way, carry on.\nLocal variables Lets get to the stack-part and start with local variables. When we have a memory-area to store data in the problem isn\u0026rsquo;t really to store the data, it is how to make it nice to use.\nAs all the above mentioned libs, the same goes for coro, you can\u0026rsquo;t just make a local variable and expect it to work\nvoid some_game_object_behavior( coro* co, void*, void* ) { int my_counter = 0; co_begin(co); printf(\u0026#34;whoo %d\\n\u0026#34;, ++my_counter); co_yield(co); printf(\u0026#34;whoo %d\\n\u0026#34;, ++my_counter); co_yield(co); printf(\u0026#34;whoo %d\\n\u0026#34;, ++my_counter); co_yield(co); co_end(co); } One might expect for this to print:\nwhoo 1\nwhoo 2\nwhoo 3\nBut it will print\nwhoo 1\nwhoo 1\nwhoo 1\nWhy? If you read the article coroutines in c ( you did read it right? ) then you see the problem. The coroutines build on calling the function over and over until it exits at the end. On each call it will initialize a local variable to 0, jump to the last position in the function, increment and print.\nThats not good now, is it? \u0026ldquo;Didn\u0026rsquo;t you mention solving this with the stack\u0026rdquo; you might think and that is correct. coro has a pair of functions (actually a macros) called co_locals_begin()/co_locals_end() that is used like this\nvoid some_game_object_behavior( coro* co, void*, void* ) { co_locals_begin(co); int my_counter = 0; // could be any amount of variables here! co_locals_end(co); co_begin(co); printf(\u0026#34;whoo %d\\n\u0026#34;, ++locals.my_counter); co_yield(co); printf(\u0026#34;whoo %d\\n\u0026#34;, ++locals.my_counter); co_yield(co); printf(\u0026#34;whoo %d\\n\u0026#34;, ++locals.my_counter); co_yield(co); co_end(co); } These macros will declare a local struct and instantiate a reference to one of these called locals, and guess where that reference is pointing, into the stack! This variable will only be allocated from the stack when entering the function for the first time, in the following calls it will just be fetched from the stack.\nWhat this means is that we will have a struct that will be the same between all calls to our coroutine, that is not exposed to the calling code and take the burden of keeping track of this away from the caller.\nIt might be interesting to have a look at how the macro work as well, if we just expand it and look at what is generated.\nvoid some_game_object_behavior( coro* co, void*, void* ) { struct _co_locals { int my_counter = 0; }; if(co-\u0026gt;call_locals == nullptr) { co-\u0026gt;call_locals = _co_stack_alloc( co, sizeof(_co_locals), alignof(_co_locals)); new (co-\u0026gt;call_locals) _co_locals; } _co_locals\u0026amp; CORO_LOCALS_NAME = *((_co_locals*)co-\u0026gt;call_locals); co_begin(co); // ... function ... co_end(co); } As you can see it just declare a local struct and put everything between co_locals_begin()/co_locals_end() into it. Then, if it is the first call, allocate data from the stack at the correct size/alignment. By placing the values in a struct we can put all of this in one declare call + we get size/alignment of the entire block for free from the compiler.\nAlso, since c++ now supports \u0026lsquo;inline\u0026rsquo; initialization ( I guess there is a fancier name for it ) of member-variables we can just write out or variables, set initial values and use placement new to initialize the values.\nNote to the C++:ers out there, currently no destructor is run on the locals but I guess that could be implemented in co_end() if needed.\nsub-calls With local variables out of the way, how about calling another coroutine function from the first one? Well, just to state the obvious calling an ordinary function is just doing the call if someone was wondering. However say that you want to call a function that can, by itself, yield execution?\nvoid some_game_object_sub_behaviors1( coro* co, void*, void* ) { // ... do stuff ... wait_for_timer(); // how this is implemented is up to the user ;) // ... do other stuff ... } void some_game_object_sub_behaviors2( coro* co, void*, void* ) { // ... do other cool stuff ... wait_for_timer(); // how this is implemented is up to the user ;) // ... DAMN THIS IS SOME COOL STUFF GOING ON HERE ... } void some_game_object_behavior( coro* co, void*, void* ) { co_begin(co); // ... function ... if(rand() % 1) { // some_game_object_sub_behaviors1()? } else { // some_game_object_sub_behaviors2()? } co_end(co); } Lucky for us we have the stack and co_call()! co_call() will allocate a coro-struct on the coroutine-stack and execute that just as any other coroutine. However it has some differences from co_init()+co_resume(). First of all, if it returns on the first call the caller will not yield, it will just continue. If it do yield it will be resumed by co_begin() of the caller until it completes and then the caller will continue at the yield-point introduced by co_call(). The resume of the sub-call could also have been done in the top-level co_resume() call but I decided to do it from the caller just to preserve the callstack for debugging. When the sub-call completes the stack will be reset to the point where co_call() allocated its coro-struct.\nThe above code will then be\nvoid some_game_object_behavior( coro* co, void*, void* ) { co_begin(co); // ... function ... if(rand() % 1) co_call(co, some_game_object_sub_behaviors1); else co_call(co, some_game_object_sub_behaviors2); co_end(co); } call-arguments So how about argument to coroutines? You guessed it, lets just pass them on the stack! Both co_init() and co_call() has versions that accepts a pointer to an argument + size/alignment. Example\nvoid some_game_object_move_on_path( coro* co, void*, int* path_index ) { move_me_on_path(*path_index); // maybe this will yield until movement is complete! } void some_game_object_behavior( coro* co, void*, void* ) { int path_to_take; // need to be declared before co_begin(), see below =/ co_begin(co); // ... function ... path_to_take = rand() % 5; co_call((co_func)some_game_object_move_on_path, \u0026amp;path_to_take, sizeof(int), alignof(int)); co_end(co); } The above will allocate space for the int and copy it onto the stack, and run some_game_object_move_on_path. The last argument to a co_func will be its arguments, or nullptr if not used. An alert reader might have noticed that the argument is copied onto the stack and that is true\u0026hellip; and its copied by memcpy so keep the arguments simple. I guess you could add lots of c++ magic to move types and yada yada but I haven\u0026rsquo;t needed that. IHMO keeping types memcpy-able usually keeps code simpler and easier to work with!\nNote: there is also a version of co_call() and co_init() that deduce sizeof() and alignof() from arg.\nAgain, no destructor will be run for the argument! Lastly note the cast to (co_func)! I guess that this is not everyones cup of tea but personally I\u0026rsquo;d rather take the cast there than in the function itself but I guess that is a matter of taste.\nRunning out of stack! So what happens when/if we run out of stack, for example allocating locals, args or doing a co_call()? coro will handle that gracefully and yield the coroutine at a point before the point of allocation. When this happen co_resume() will return as usual and the state can be checked by co_stack_overflowed() and that can then be handled by the user. The simplest might just be to ASSERT() but there is also co_stack_replace() if you feel fancy and want to grow the stack.\nAn example of how this might work\nvoid run_me() { uint8_t original_stack[128]; coro co; co_init(\u0026amp;co, original_stack, sizeof(original_stack), some_func); while(!co_completed(\u0026amp;co)) { co_resume(\u0026amp;co); if(co_stack_overflowed(\u0026amp;co)) { void* old = co_stack_replace(\u0026amp;co, malloc(co.stack_size * 2), co.stack_size * 2); if(old != original_stack) free(old); } } if(co.stack != original_stack) free(co.stack); } a note on \u0026lsquo;waiting\u0026rsquo; I mentioned above that I would like to be able to do things such as wait_for( timeout, move_to ). That is however something that I have mostly left out of coro. Why you ask? Well, I can\u0026rsquo;t really know how the user structures their code, how do they want to update the coroutines etc. If I would have supported something like that the lib would have become bigger and more \u0026lsquo;opinionated\u0026rsquo;, maybe it would have needed an update and a manager of some kind etc. That would have brought the lib from being a simple building-block to something more \u0026ldquo;framework:y\u0026rdquo; and that is not my intent. Maybe someday I\u0026rsquo;ll do something like that but then it will be built upon coro not built into it. There is however one small helper for building this kind of code, and that is co_wait(). co_wait() is basically a co_yield() that also sets a flag on the coroutine. This flag is also propagated through the currently running coroutine-callstack so that the user can do co_waiting(\u0026amp;co) at the top-level and see if it is waiting for something. This flag will be cleared on the next call to co_resume(). I think this little addition will be enough to build your own system on top of it if needed.\nConclusion First of all I need to say that I\u0026rsquo;m curious to see if it really works when I actually start to use it ;) I.e. my next task is to actually use this for something productive ( nope haven\u0026rsquo;t done that yet! ). IMHO it feels promising but we\u0026rsquo;ll see.\nSecondly let\u0026rsquo;s take a look at some pros/cons of this approach.\nPro: No platform specific code This is IMHO a big win for a smaller team ( in this case me ). No need to support low-level asm-code to switch stacks and save registers. No worries about \u0026ldquo;what happens if we start porting to a new platform, can we do the same thing there?\u0026rdquo;.\nPro: Not much code Also it is quite small ( at the time of writing 280 lines of code + 345 lines of comments ) and that is always a good thing for maintenance and \u0026ldquo;ease of use\u0026rdquo;.\nCon: Easy to mess up locals It is easy to mess up your local variables as it is second nature for every one of us to just declare a variable and expect it to keep its value :) My guess however is that you learn quickly and hopefully co_locals_begin()/co_locals_end() make it a bit easier.\nCon: Macro-heavy Personally I\u0026rsquo;m not that afraid of macros but I know some are. Also in this case they require you to follow quite a few rules and if you break them you end up with quite hard to understand errors. Again I think this is something that you learn but the more of you on your team the more people that have to learn and the fudge up a few times.\nAn macro-related error that can be quite hard to understand if you are new to the code is this\nvoid some_game_object_behavior( coro* co, void*, void* ) { co_begin(co); // ... function ... int path_to_take = rand() % 5; printf(\u0026#34;%d\\n\u0026#34;, path_to_take); co_yeald(co); co_end(co); } This code looks perfectly valid but generates this on my currently installed gcc.\ntest/test_coro.cpp: In function ‘void some_game_object_behavior(coro*, void*, void*)’: test/test_coro.cpp:43:16: error: jump to case label [-fpermissive] co_yield(co); ^ test/test_coro.cpp:40:9: note: crosses initialization of ‘int path_to_take’ int path_to_take = rand() % 5;\nAlso stepping through the co_***-macros while debugging is far from pleasant, hopefully that is my problem and not my users :)\nCon: no type-safety for arguments Currently there is no real type-safety between args passed to co_call()/co_init() and the actual function used as a coroutine callback. I would like to have that but I\u0026rsquo;m not really sure that it is doable? Any ideas for solutions would be appreciated ( easy on the meta-programming please ) !\nFinal note I think this turned out nicely and hope that its something that might be useful for some of you. On a bigger team with more resources, would I use this? Maybe? I think a full-scale stack-register switch might be a better solution but that has its own caveats ( TLS-variables for example ).\nAny thoughts or suggestions? I would love to hear about it! Please hit me up on twitter or post in the coro issue-tracker! And remember, there will be bugs, there always is!\nCheck it out https://github.com/wc-duck/coro!\n"
            }
    
        ,
            {
                "id": 5,
                "href": "http://kihlander.net/post/printf-based-tostr-on-the-stack/",
                "title": "printf-based TOSTR on the stack",
                "section": "post",
                "date" : "2018.05.15",
                "body": "As I might have written before I like printf-style string-formating. It\u0026rsquo;s imho the most convenient way to format strings and it can be really powerful if needed. However something that can be a bit tedious is output:ing \u0026ldquo;composite\u0026rdquo; values such as a vec3 or quaternion as there will be quite a bunch of repetition.\nprintf(\u0026#34;{ %.2f, %.2f, %.2f }\u0026#34;, vec.x, vec.x, vec.z); Doing this for multiple values really get verbose and its easy to make simple copy-paste-errors ( see above! ).\nI have read/looked at a whole bunch of string-formating libs and \u0026ldquo;tostr()\u0026rdquo; implementations, usually in c++, returning an std::string and/or overloading operator\u0026lt;\u0026lt; for writing to std::ostream etc and not really liking any of them ( forcing dynamic allocation for known sized outputs for example, yuck! ).\nBut complaining is easy, time to be constructive and get to some suggestions on how this can be done instead.\nBYTES2STR() I have found that most of these problems can be solved with a small trick, introducing a struct with the storage for the string. I will start introducing this with a simple macro to turn a size_t to a string in the format \u0026quot;234 bytes\u0026quot;, \u0026quot;2.9 kB\u0026quot; or \u0026quot;234 GB\u0026quot;.\nenum { BYTES_PER_KB = 1024, BYTES_PER_MB = 1024 * BYTES_PER_KB, BYTES_PER_GB = 1024 * BYTES_PER_MB }; struct _bytes_to_human { char str[64]; _bytes_to_human( size_t bytes ) { if ( bytes \u0026gt; BYTES_PER_GB ) snprintf( str, sizeof(str), \u0026#34;%.02f GB\u0026#34;, (double)bytes * ( 1.0f / (double)BYTES_PER_GB ) ); else if( bytes \u0026gt; BYTES_PER_MB ) snprintf( str, sizeof(str), \u0026#34;%.02f MB\u0026#34;, (double)bytes * ( 1.0f / (double)BYTES_PER_MB ) ); else if( bytes \u0026gt; BYTES_PER_KB ) snprintf( str, sizeof(str), \u0026#34;%.02f kB\u0026#34;, (double)bytes * ( 1.0f / (double)BYTES_PER_KB ) ); else snprintf( str, sizeof(str), \u0026#34;%zu bytes\u0026#34;, bytes ); }; }; #define BYTES2STR( bytes ) _bytes_to_human( bytes ).str This can now be used simply as follows\nprintf(\u0026#34;you have allocated %s\u0026#34;, BYTES2STR(allocated_bytes)); What we did here is to introduce a helper-struct containing the storage for the generated string and a macro to hide a bit of ugliness. Simple and easy to read and work with and I feel fairly confident when I say that the compiler will handle this will, NICE :)\nExtending to a more general TOSTR() But can this be extended to be a general and extensible solution? Would I write this article if I didn\u0026rsquo;t believe that it was? Of course it is and with a really small amount of code as well :)\nOur goal here is to be able to have one macro, TOSTR(obj), that take an object that has an implementation defined with TOSTR_DEFINE_TYPE_FUNCTION that defines how to convert the type to string and reserve space for that string on the stack.\nIf you just want the code or think it is easier to read the code directly here is a link to a github repo.\nhttps://github.com/wc-duck/tostring.\nOnto the code/implementation then!\nSo lets say that we have a vec3-struct that we want to add TOSTR() support to. That is as simple as using the macro TOSTR_DEFINE_TYPE_FUNCTION as follows.\nstruct vec3 { float x; float y; float z; }; // declare with type to implement for and the amount of bytes that // is needed in the output-string. TOSTR_DEFINE_TYPE_FUNCTION(vec3, 64) { // the end of the macro-expansion expects you to declare how // to write the output value. // // you will get passed an output-buffer as \u0026#39;out\u0026#39; ( with space // for the requested 64-chars ) and a reference to the value // to print as \u0026#39;value\u0026#39;. // // \u0026#39;out\u0026#39; has one member-function called \u0026#39;put\u0026#39; that has a // printf-like format. ( yes, that makes it out.put :) ) out.put(\u0026#34;{ %.2f, %.2f, %.2f }\u0026#34;, value.x, value.y, value.z); } The macro will declare a static constant for the declared type with the size like this, but for a few different cases ( vec3, const vec3, vec3\u0026amp; and const vec3\u0026amp; )\ntemplate\u0026lt;\u0026gt; struct _TOSTR_type_size\u0026lt;vec3\u0026gt; { enum { STRING_SIZE = 64 }; }; And it also declare a function with this signature ( using the code in {} after the macro as its body )\ninline void _TOSTR_type_impl( _TOSTR_builder\u0026amp; out, const vec3\u0026amp; value ); Finally we have the TOSTR(obj)-macro that will create a temporary buffer on the stack, fetching its size from _TOSTR_type_size\u0026lt;decltype(obj)\u0026gt;::STRING_SIZE and pass that to the _TOSTR_type_impl that will use overloading to select the correct implementation.\nWhat we can simply do now is just use TOSTR() as expected with vec3.\nprintf(\u0026#34;player: pos = %s, velocity = %s\u0026#34;, TOSTR(player_pos), TOSTR(player_vel)); // ... or ... printf(\u0026#34;player: pos = %s, velocity = %s\u0026#34;, TOSTR(player.pos()), TOSTR(player.vel())); that would output something like: \u0026quot;player: pos = { 11.0, 12.99, 13.37 }, velocity = { 0.14, 2.35, 3.71 }\u0026quot; ( depending on the actual position and velocity of the player hopefully ;) )\nbtw, they also \u0026ldquo;stack\u0026rdquo; quite well such as:\nstruct aabb { vec3 min; vec3 max; }; TOSTR_DEFINE_TYPE_FUNCTION(aabb, 128) { out.put(\u0026#34;{ %s, %s }\u0026#34;, TOSTR(value.min), TOSTR(value.max)); } Any negatives? The biggest draw-back in my opinion is the fact that the lifetime of the generated string is only during the current expression, i.e. you can\u0026rsquo;t \u0026ldquo;save\u0026rdquo; your string to use later. I.e. this is valid code but undefined behavior.\nconst char* vec_str = TOSTR(my_vec); printf(\u0026#34;%s\u0026#34;, vec_str); This since the macro defines a temporary variable to hold the value.\nAlso the fact that overflow might happen and you will get truncated output. I think this is a smaller problem as in many cases ( as the ones above and many more ) you actually know in advance the string-length that you will be generating.\nIf you find the overflow issue as a big issues it would be quite easy to add an \u0026ldquo;dynamic-alloc on overflow\u0026rdquo; to the system.\nI also know that some has problems with printf and friends all together as it is not \u0026ldquo;typesafe\u0026rdquo; etc. Imho that is mostly a solved problem by modern compilers that do type-checks in compile-time for you on these. But that is my opinion :)\nFinally there might be some objections to the template-usage in the implementation but I think it is at a reasonable level, but I guess that it can be solved in other ways if you think this is a problem.\nConclusion This might not be anything new but it is a small trick that I haven\u0026rsquo;t seen that much in the wild and that has made my own code \u0026ldquo;better\u0026rdquo; imho. It might not be to everybodys taste but hopefully someone has got a new tool to their toolbox!\nAs usual, don\u0026rsquo;t be afraid to reach out to me at twitter, github any other channel that you might know of!\n"
            }
    
        ,
            {
                "id": 6,
                "href": "http://kihlander.net/post/a-story-about-an-unexpected-abi-break/",
                "title": "A story about an unexpected ABI break",
                "section": "post",
                "date" : "2017.11.15",
                "body": "This is the story of an unexpected ABI break that I thought would be worth documenting.\nAt Avalanche we use a small class wrapping 32bit hashes called CHashString, it is basically just a wrapper around uint32_t and one should be able to treat it as a uint32_t in code except for operations that do not make sense on a hash-value.\nWhy would you want a class like this you might ask, well we use it for adding a const char* c_str()-function that can be used in logging and also we use it to add custom natvis-support in visual studio so that you can just hover a CHashString and have a lookup of the hash-value performed.\nHowever this is not about how we use it, but how things can break in unexpected ways.\nAs a bit more background it should be mentioned that a big part of Avalanches internal libraries are distributed pre-compiled to our game-projects with all the positives and negatives that brings with it. For example when deploying a middle-version fix we \u0026ldquo;promise\u0026rdquo; to our projects that we do not break the ABI of the library, i.e. you should be able to link with any 5.x.x if you only depend on 5.x.x.\nOur CHashString was basically defined something like this\nclass CHashString { uint32_t m_Hash; public: explicit CHashString(uint32_t hash) : m_Hash(hash) {} CHashString\u0026amp; CHashString(CHashString\u0026amp; other) { m_Hash = other.m_Hash; } ... more constructors ... ... more functions ... bool operator ==(const CHashString other) const { return m_Hash == other.m_Hash; } } As an earlier brain-fart/didn\u0026rsquo;t-think-about-that someone added the copy-constructor, something that made this class non-trivially-copyable, i.e. std::is_trivially_copyable would fail. This would lead to putting it in some containers would not make it as performant as it should have been ( and it couldn\u0026rsquo;t even live in some containers ).\nAs the fixy kind of guy one am I said to my self \u0026ldquo;I can fix this, how hard can it be?\u0026rdquo;. We decided that we should just remove that un-needed copy-constructor since a default copy-constructor would do the same thing. Said and done, be gone with you!\ncheck-in!\ndeploy!\ngo for coffee!\n\u0026hellip;\n\u0026hellip;\n\u0026hellip;\nCome back to crashing projects!\nSad panda!\nLuckily for me it is easy to lock down versions of distributed libs so we could quickly fix the issues on the projects by locking down to the previous version.\nAt this time we are scratching our heads quite a bit, our thinking being that even if one part of the code calls the old way of copy-constructing an object the end result should be the same in memory\u0026hellip; And to make things worse, most things seem to work.\nTime to bring out the debugger!\nI build a debug-build of one of our projects and after some time, thanks to some log-messages, I find a spot that behaves REALLY fishy!\nCHashString one_hash(0x12345678); CHashString another_hash(0x12345678); // ... later in the code ... if( one_hash == another_hash ) { do_stuff(); } do_stuff() is NEVER called!?! I.e. stuff is never done, and we all know that our job is mostly about getting stuff done ;)\nThe debugger tell me that the 2 values are the same! What is going on here? After checking the assembly and stepping the code quite a few times we can determine that when we removed the copy-constructor MSVC decided that it should pass CHashString in register instead of by pointer to stack. So what our operator== that take CHashString by-value ends up doing is comparing one of the hashes to half the stack-address of the other variable :)\nThis since this code is defined in one of our pre-compiled libraries and the implementation of operator== ends up in our main executable that is built from latest the lib and the exe disagrees on how to pass values to the function!\nAs expected this works in a release build where the code is inlined, but in that case we had other functions where how CHashString was passed was an issue.\nWhat can we learn from this? ABI-issues can show its ugly face when you least expect it and compilers do the darnedest things!\nWell, that was part of my day, how was yours? Feel free to hit me up on twitter or something if you want to give me a comment about this!\n"
            }
    
        ,
            {
                "id": 7,
                "href": "http://kihlander.net/post/builtin-resources-and-the-resource-system/",
                "title": "Builtin resources and the resource-system",
                "section": "post",
                "date" : "2017.08.07",
                "body": "I have written, in passing, about the resource-system and VFS ( Virtual File System ) I use in my own game-engine. This time it will however not be \u0026ldquo;in passing\u0026rdquo; but will dig down a bit deeper into one \u0026ldquo;feature\u0026rdquo; in it that I find kind of neat. I\u0026rsquo;m sure it has been done before but I have not seen it myself somewhere else. I\u0026rsquo;ll be writing about how I handle builtin resources in the engine.\nWhen talking about a \u0026ldquo;builtin resource\u0026rdquo; I refer to resources generated by code and not read from files on disk such as a red.png or a cube.mesh. Resources read from disk I\u0026rsquo;ll refer to as \u0026ldquo;assets\u0026rdquo;. Builtin resources might be useful while prototyping in cases like \u0026ldquo;Oh, I\u0026rsquo;m creating an new enemy-type but I need some place-holder mesh and material while testing and I just do not want to model a cube and paint a red texture\u0026rdquo;\nHow is the resource-system structured? I think that we will have to start with describing how the resource-system works, just to get some fundamentals down. In the bottom we have the VFS, or Virtual File System. That is just a system to hide access to \u0026ldquo;some kind of file-storage\u0026rdquo; ( file system, HTTP, archive-file etc ) where all files are referenced as an absolute path such as /assets/texture/apa.tex2d.\nThe VFS is in turn used by the resource-system that is a system with 2 purposes, creating/maintaining resource-containers and \u0026ldquo;turning VFS-paths to resources that can be used in engine\u0026rdquo;. I.e. load file via VFS and pass the data on to a callback, maintain a \u0026ldquo;handle\u0026rdquo; returned by said callback. A resource-container is just a collection of resources used to group resources such as base_resources and level_1_data etc.\nWell, as you can see it\u0026rsquo;s fairly traditional :)\nHow about them builtin resources then! So how do the engine handle the builtins then? Well, the paths to the VFS is always absolute and start at the root, i.e. start with a \u0026lsquo;/\u0026rsquo;. That opens up for \u0026ldquo;tagging\u0026rdquo; paths as special. So if the path is not starting with a \u0026lsquo;/\u0026rsquo; it is not a valid VFS path and we could use that in the resource-system itself. As I currently have it implemented the resource-system supports to path-formats:\n/absolute/VFS/path - a file path in the VFS. :res_type:type_specific_desc - a builtin for a specific type.\nSo if the path starts with, for example, :tex2: or :mesh: then the resource system just pass all that is right of the :res_type: to a specific create_builtin_callback for the resource-type registered for that type. Then it is up to the loading-code of the type ( tex/mesh/material etc ) to do what it pleases with the rest of the string. The callback for the specific type then just goes ahead an creates the desired resource and returns a handle to it in the exact same way as when it creates the resource from and asset or report an error back to the resource-system on error. I have ended up with just having all these paths \u0026lsquo;_\u0026rsquo;-separated and starting with a \u0026ldquo;base type\u0026rdquo; and followed by parameters, such as :mesh:cube_dim_(1,2,1)_pos_(0,1,0) to create a cube with dimensions 1,2,1 and center at 0,1,0 or :tex2d:solid_col_FF0000FF to create a solid red 2d-texture.\nPros and cons with the system pros Works with all systems referencing a resource type. I.e. you only have to implement \u0026ldquo;builtins\u0026rdquo; once for each type and whenever another system reference a resource it works with both assets and builtins automagically. Both \u0026ldquo;particles\u0026rdquo; and \u0026ldquo;renderables\u0026rdquo; can access builtin meshes via the same code for example. So when referencing a resource by VFS-path it will automagically work with builtins and by that works transparently from content.\nAutomatically hooks in to all parts of the resources system. You will get all your builtin resources to use the same allocators and the ordinary assets, instance sharing will work ( 2 \u0026ldquo;things\u0026rdquo; reference :tex2d:solid_col_FF0000FF and they will share texture-instance, debug-views showing loaded resources will show builtins, getting memory-statistics per container/resource-type works out of the box. In short, if it works with assets from disk it works with builtins.\ncons Resources need to be identified by strings. I would consider this the biggest issue and may make it unfeasible in a AAA-context where most of the times resources are identified by other types of ID:s. For most hobbyists, small-sized and mid-sized projects I don\u0026rsquo;t see that as a problem however as asset-counts and perf usually is \u0026ldquo;good enough (tm)\u0026rdquo; anyway.\nString-parsing and an undocumented \u0026ldquo;language\u0026rdquo; that is different per resource-type. This might also be a problem on a bigger team as the parsing need to handle errors well, warn clearly to the user what is wrong etc. Again on a smaller team where team-members work close together and problems ( such as error handling and error-output ) can be fixed quickly I think it should work out well. However take a note that it\u0026rsquo;s just a guess since my own projects is on a team of size 1 where all members think exactly like me ;)\nSafety? This might be an issue but nothing I have spent that much time on. As these codepaths might not be that well tested and hardened it might be a simple way \u0026ldquo;in\u0026rdquo; for a malicious person if you are concerned by that. In that case you might want to just have this enabled during development.\nConclusion I\u0026rsquo;ll just conclude by saying that this is a system/feature that has worked out really well for me on my own stuff and has proven itself to be really useful. As mentioned above it is really helpful to be able to reference \u0026ldquo;a red texture\u0026rdquo; or \u0026ldquo;a cube\u0026rdquo; directly via assets.\nWhat do you think? Has this been done before? Any other thoughts? Hit me up on twitter and tell me ( if you do it in a civil way of course! ;) )\n"
            }
    
        ,
            {
                "id": 8,
                "href": "http://kihlander.net/post/utf8_lookup-writeup/",
                "title": "utf8_lookup, a write up.",
                "section": "post",
                "date" : "2017.06.26",
                "body": "I saw this blog post a while ago A Programmer’s Introduction to Unicode, a really great write up that is a worth a read for anyone interested in the subject! So go ahead and read that now even as it might not be super important for what I am about to write about here :)\nReading this reminded me of an old project of mine that I think is a bit novel and deserves, at least, a write up. I am talking about utf8_lookup, a small lib to translate utf8 chars into offsets into a table.\nIt sprung out of the need to convert utf8-strings into bitmap-font glyhps for rendering. I.e. build some kind of data-structure out of a list of supplied codepoints and then use that to translate strings into a lists of indices of valid glyphs or 0 if the glyph wasn\u0026rsquo;t present in the original codepoint-list, i.e. rendering a bitmap font! That is what I have been using it for but I guess there might be other uses for a sparse lookup structure like this as well.\nIn short, this is what I have used it for (simplified):\nvoid render_text(const uint8_t* text) { utf8_lookup_result res[256]; size_t res_size = ARRAY_LENGTH(res); const uint8_t* str_iter = text; while( *str_iter ) { str_iter = utf8_lookup_perform_scalar( table, str_iter, res, \u0026amp;res_size ); for( size_t g = 0; g \u0026lt; res_size; ++g ) render_glyph( some_glyph_data[res[g].offset] ); // some_glyph_data might contain things such as uv:s etc. } } The properties of the lib are:\nlow memory usage one memory chunk for the lookup structure with all (one) allocations done by the user. fairly quick ( we will get in to this later under \u0026ldquo;performance\u0026rdquo; ) all non-found codepoints should map to offset 0 so that one can place a default-glyph there. However I hadn\u0026rsquo;t done any major profiling of the lib and I hadn\u0026rsquo;t compared it to some other approaches to doing the same thing. Time to change that!\nHow does it work? So now lets get to the meat of the post, how does it work?\nThe lib basically builds compact search tree based on the ideas of a Hash Array Mapped Trie, HAMT for short, where each level of the tree is based on each byte of an utf8-char.\nAs stated earlier the entire lookup structure is stored as one buffer, a buffer with the following layout.\nitem_cnt[uint64_t], availability-bits[uint64_t[item_cnt]], offsets[uint16_t[item_cnt]]\nitem_cnt the amount of items in the following lists, kept as uint64_t for alignment reasons. availability-bits collection of bit-fields of what codepoints that are available in the lookup per \u0026ldquo;octet-byte\u0026rdquo;. offsets depending on the octet of the current char to translate and step in the translation-process the next offset in availability-bits or start of result-offset. By octet I refer to how many bytes the current utf8-char is consisting of.\nThe first section of our availability-bits is the \u0026ldquo;root\u0026rdquo; of our lookup-table where a small table is used to find where to start the lookup. As octet one ( i.e. ASCII ) can have 128 possible values in utf8 ( first bit is 0 ) we need two slots in the availability bits where all other octets first byte fit in one 64-bit slots.\nSo what is stored is something like this: [ octet1 lower start ] [ octet1 higher start ] [ octet2 start ] [ octet3 start ] [ octet4 start ] \u0026hellip; [ octet2 bit1 ] [ octet2 bit2 ] \u0026hellip; [ octet3 bit1 ] \u0026hellip; [ octet3 bit1 bit2 ]\nWhat we are actually storing is info about groups of codepoints in subsequent bytes. I.e. we split the range of codepoints in chunks of 64 and if any char in that group is available in the table that bit is set. This is true except in the \u0026ldquo;leaf\u0026rdquo; where it represent if the actual codepoint exists. In short we have built a tree-structure with all levels having between 0 and 64 branches.\nAlso, if an entire 64-bits chunk is 0, we do not store it at all so there will be no 64-bit chunk that is 0, if there is I have a bug :)\nNow to find the actual offset that are to be our result, we store offsets to where the next 64-bit chunk for the next byte in our codepoint is stored. By then storing all subservient levels in the tree after each other as such:\ni will do this for 8 bits just to fit on the page :)\navail_bits[some_index] = [00010110] offset[some_index] = 16\navail_bits[16-18] = is the next level in the tree offsets[16-18] = offsets to the next level in the tree or final result-offsets.\nAs we only store one offset per level we need a way to find what item we need, but we do not want empty elements for the 0-bit. What we can do then is use base_offset + bits_set_before_checked_bit(), an operation that can be performed really fast by modern hardware via the popcnt-instruction and fairly quick with some smart code if popcnt is not available.\nSo the inner loop of the algorithm will look as follows.\n// table telling where to start a lookup-traversal depending on how many bytes the current utf8-char is. // first item in the avail_bits is always 0, this is used as \u0026#34;not found\u0026#34;. If sometime in the lookup-loop // a char is determined that it do not exist, i.e. a bit in the avail_bits-array is not set, the current // lookup index will be set to 0 and reference this empty bitset for the rest of the lookup. // // This was done under the assumption that you mostly do lookups that \u0026#34;hit\u0026#34; the table, i.e. you will need // to do all loop-iterations so instead of branching, just make the code always loop all iterations. // // if this is a gain is something to actually be tested. static const uint64_t START_OFFSET[4] = { 1, 3, 4, 5 }; // pos is the current position in the utf8-string to perform a lookup for. uint8_t first_byte = *pos; int octet = UTF8_TRAILING_BYTES_TABLE[ first_byte ]; static const uint64_t GROUP_MASK[4] = { 127, 63, 63, 63 }; static const uint64_t GID_MASK[4] = { 63, 31, 15, 7 }; uint64_t curr_offset = START_OFFSET[octet]; uint64_t group_mask = GROUP_MASK[octet]; uint64_t gid_mask = GID_MASK[octet]; for( int i = 0; i \u0026lt;= octet; ++i ) { // make sure that we get a value between 0-63 to decide what bit the current byte. // it is only octet 1 that will have more than 6 significant bits. uint64_t group = (uint64_t)(*pos \u0026amp; group_mask) \u0026gt;\u0026gt; (uint64_t)6; // mask of the bits that is valid in this mask, only the first byte will have a // different amount of set bits. Thereof the table above. uint64_t gid = (uint64_t)(*pos \u0026amp; gid_mask); uint64_t check_bit = (uint64_t)1 \u0026lt;\u0026lt; gid; // gid mask will always be 0b111111 i.e. the lowest 6 bit set on all loops except // the first one. This is due to how utf8 is structured, see table at the top of // the file. gid_mask = 63; ++pos; // index in avail_bits and corresponding offsets that we are currently working in. uint64_t index = group + curr_offset; // how many bits are set \u0026#34;before\u0026#34; the current element in this group? this is used // to calculate the next item in the lookup. uint64_t items_before = utf8_popcnt_impl( avail_bits[index] \u0026amp; ( check_bit - (uint64_t)1 ), has_popcnt ); // select the next offset in the avail_bits-array to check or if this is the last iteration this // will be the actual result. // note: if the lookup is a miss, i.e. bit is not set, point curr_offset to 0 that is a bitfield // that is always 0 and offsets[0] == 0 to just keep on \u0026#34;missing\u0026#34; curr_offset = ( avail_bits[index] \u0026amp; check_bit ) \u0026gt; (uint64_t)0 ? offsets[index] + items_before : 0x0; } // curr_offset is now either 0 for not found or offset in glyphs-table res_out-\u0026gt;offset = (unsigned int)curr_offset; Performance To test out the performance of the solution I have written a small benchmark app that is testing 4 different approaches to doing this and measuring some different stats\nmemory usage total amount of allocations speed GB/sec ms/10000 codepoints These benchmarks runs over quite a few texts in various languages. Downloaded from The Project Gutenberg. I have tried to get a good spread over different kind of texts using different combinations of code-pages etc.\nThe benchmarks will perform a complete \u0026ldquo;translation\u0026rdquo; of each text 100 times in a row.\nThe tested approaches for doing this are as follows\nuse utf8_lookup with a native popcnt instruction use utf8_lookup without a native popcnt instruction stuff all codepoint/offset pairs into an std::map stuff all codepoint/offset pairs into an std::unordered_map bitarray with native popcnt bitarray without native popcnt The bitarray-approach is just having a big array of uint64_t, set the bit if the codepoint exists, store an offset per uint64_t, and get the result-offset as:\nres = offsets[codepoint / 64] + bits_set_before(lookup[codepoint / 64])\nbasically utf8_lookup without compression.\nFinally its time for some numbers and charts!\nTexts used and results:\nfile codepoint count bpcp utf8_lookup bpcp bitarray bpcp std::map bpcp std::unordered_map ancient_greek.txt 222 0.891892 5.810811 40.0 30.342342 stb_image.h 95 0.505263 0.019531 40.0 23.242105 chinese1.txt 3529 0.971380 2.893171 40.0 24.451118 chinese2.txt 3540 0.959887 2.884181 40.0 24.424858 chinese3.txt 4226 0.818268 2.415996 40.0 30.209181 danish.txt 111 1.333333 11.351352 40.0 29.549549 germain.txt 133 1.413534 10.526316 40.0 27.308271 esperanto.txt 96 1.229167 13.437500 40.0 23.166666 japanese.txt 2176 1.506434 4.191961 40.0 28.232977 japanese2.txt 2438 1.506434 4.696691 40.0 29.705883 russian.txt 145 0.882759 8.896552 40.0 26.372414 big.txt 6069 0.607678 1.683968 40.0 25.894217 bpcp = bytes per codepoint\nAll tests has been run on my private machine, an Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz with 16GB DDR3 RAM running Ubuntu 14.04.5 LTS.\nAll builds has been done with g++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4.\nOptimized builds has been compiled with\ng++ -Wconversion -Wextra -Wall -Werror -Wstrict-aliasing=2 -O2 -std=gnu++0x -Wconversion -Wextra -Wall -Werror -Wstrict-aliasing=2 -O2\nAnd debug builds with\ng++ -Wconversion -Wextra -Wall -Werror -Wstrict-aliasing=2 -std=gnu++0x -Wconversion -Wextra -Wall -Werror -Wstrict-aliasing=2\nFirst lets get this out of the room, the std::map/unordered_map versions are really bad compared to the others in all measurements. That was expected but I added them to the tests as it is something that is the \u0026ldquo;first thing that comes to mind\u0026rdquo; and something I wouldn\u0026rsquo;t be surprised to see in a codebase.\nAs we can see the memory used and performance ( in GB text translated per second ) by the std::-implementations are just huge compared to the other to solutions, so lets remove them to get some more interesting charts :)\nThe charts clearly show that utf8_lookup outperforms the bitarray in all cases except pure ASCII ( stb_image.h ) when it comes to memory-usage and loses when it comes to raw lookup performance in all tests. We can also mention that the \u0026ldquo;tighter\u0026rdquo; the codepoints to lookup are, the more comparable the both techniques are. We could also plot bytes-per-codepoint vs lookup perf.\nIn this chart we can clearly see each approach \u0026ldquo;banding\u0026rdquo; on bytes-per-codepoint and lookup-perf.\nWe\u0026rsquo;ll end with mentioning performance in an non-optimized build as well, something that I find usually is lacking. OK performance in a debug-build is really something that will make your life easier and something I find to be a well worthy goal to strive for.\nIt\u0026rsquo;s the same pattern here, the std::-based solutions are just getting crushed and the simple array is by far the fastest but IMHO utf8_lookup holds its ground pretty well. A colleague of mine also pointed out that this is with gcc:s implementation of the STL, if this would have been run with some other STL implementations ( among others the one used in msvc ) the debug-results would have been even worse.\nConclusion It has been quite interesting to test and benchmark this solution. I guess the findings can be summarized as follows, if you want pure performance nothing beats a simple array ( nothing new under the sun here! ), however utf8_lookup performs really well when it comes to memory-usage.\nI also think that there might be other approaches worth testing and adding benchmarks for here and maybe some more investigations into what governs performance. My guess is cache, i.e. depending on how the indexed codepoints are distributed it could give better or worse cache-utilization.\nThere might also be gains to be had in the actual utf8_lookup implementation, for example one might change the order of how the internal items are stored to better group used memory chunks depending on access-patters. It might be interesting to generate some \u0026ldquo;heatmaps\u0026rdquo; of used codepoints for the different texts and see if a patter emerges.\nHowever as I am, depending on when your read this, the father of 2 this is all that I have the time and energy for now and it is good enough for the small things I use it for.\nI hope that this might be useful for someone, maybe it can be used for something other than what I have used it for? And if there is something to really take away from this is that base_offset + (popcnt(bits_before)) is a really sweet technique that can be used for many things :)\nHave I missed any benchmark approach? Any improvements that I could do? Anything else? Feel free to contact me on twitter!\n"
            }
    
        ,
            {
                "id": 9,
                "href": "http://kihlander.net/post/why-i-prefer-inline-forward-daclares-in-c/",
                "title": "Why I prefer inline forward-declares in C++",
                "section": "post",
                "date" : "2016.11.14",
                "body": "Time for a short post on how I usually do the humble forward declare in C++. I guess this is not something new but it is something I usually do not see in others code so it feels worth sharing.\nSo lets start of with just defining what we are talking about just to get everyone on the same page, we are talking about declaring only a class/struct name to the compiler and not having to provide the entire class/struct declaration. Mostly used as a compile-time optimization or to handle circular deps etc.\nA simple example:\n// forward declare this struct. struct a_forward_declared_struct; struct my_struct { a_forward_declared_struct* a_forward_declared_pointer; }; void my_func( a_forward_declared_struct* another_pointer ); We\u0026rsquo;re all used to see this kind of code, nothing new under the sun. I however like to write it like this:\nstruct my_struct { struct a_forward_declared_struct* a_forward_declared_pointer; }; void my_func( struct a_forward_declared_struct* another_pointer ); I don\u0026rsquo;t know if inline-forward-declare is the correct term, but we\u0026rsquo;ll use that until I\u0026rsquo;m told otherwise ;)\nSo what is better with this more verbose variant? Well, I have 2 reasons:\nIt do not \u0026ldquo;leak\u0026rdquo; definitions into the global namespace. When usage is removed, so is the forward declare. Lets go through them one-by-one.\nIt do not \u0026ldquo;leak\u0026rdquo; definitions into the global namespace. The big thing here is that we can\u0026rsquo;t break other code by removing our forward declares. Say that you have this code:\n\u0026lt;header1.h\u0026gt;\nstruct a_forward_declared_struct; void my_func1( a_forward_declared_struct* another_pointer ); \u0026lt;header2.h\u0026gt;\nvoid my_func2( a_forward_declared_struct* another_pointer ); // OH NOES, we forgot our forward declare! file.cpp\n#include \u0026#34;header1.h\u0026#34; #include \u0026#34;header2.h\u0026#34; #include \u0026#34;a_forward_declared_struct.h\u0026#34; // defining the actual struct. void a_function( a_forward_declared_struct* ptr ) { my_func2( ptr ); } Now we work with our code and refactor my_func1() to no longer take a pointer to a a_forward_declared_struct and removing the forward declare. By doing this we break file.cpp since \u0026ldquo;header2.h\u0026rdquo; is now \u0026ldquo;incomplete\u0026rdquo;. This might not be a big issue in a smaller code-base but in a bigger one (especially one using unity-builds, batch-builds or whatever you want to call them ) this can pop up on another colleagues machine after you have submitted your code.\nIf instead you would have used inline forward-declares header2.h would never have compiled to begin with so the initial implementer would not have missed the needed declarations.\nWhen usage is removed, so is the forward declare. The second improvement over the \u0026ldquo;ordinary\u0026rdquo; declarations is the fact that they are automatically removed when they are no longer needed since they are part of the actual code.\nHow many times haven\u0026rsquo;t we all found forward declares that no one uses ( and no one want to remove due to point 1 ;) ).\nSome thing like:\nclass vec3; struct i_have_no_vec3 { int apa; int kossa; // I had a vec3 here a few years ago! }; Final words Are there any drawbacks? Well, except for being slightly more verbose, the only one I can think of is that it do not work together with namespaces. For me that is no real problem since I really do not like namespaces to begin with ( topic for another rant/blog-post? ) but if you do this tip is not as useful. If you mix and match I would still recommend using inline forward-declares where possible and fallback to namespace:d declares when you have to.\nnamespace foo { class bar; }; Do you agree, am I totally wrong? Feel free to tell me on twitter!\n"
            }
    
        ,
            {
                "id": 10,
                "href": "http://kihlander.net/post/compile-time-hashes-in-c-im-not-convinced/",
                "title": "Compile-time hashes in c++, im not convinced!",
                "section": "post",
                "date" : "2016.09.24",
                "body": "I recently read a blogpost about compile-time string-hashes and constexpr and I\u0026rsquo;m still not convinced and see no real reason to leave my old and true friend the script :)\nSo first of lets look at the problem we want to solve. We want a way to do things like this and not pay the runtime cost ( and in this case just compile! ).\nvoid my_func( uint32_t val ) { switch( val ) { case HashOfString(\u0026#34;some_string\u0026#34;): do_some_stuff(); break; case HashOfString(\u0026#34;some_other_string\u0026#34;): do_some_other_stuff(); break; } } Simple enough. What seems to come up over and over again is ways of doing this with the compiler compile-time and now recently just marking HashOfString as constexpr and \u0026ldquo;trust the compiler\u0026rdquo;. The solution I usually fall back to is to just have a text-file where each line is hashed with a custom script and written to a .h file with values such as:\nmy_hashes.hash\nsome string some other string my_hashes.hash.h\n#pragma once #define HASH_some_string 0xABCD0123 // hash of \u0026#34;some_string\u0026#34; #define HASH_some_other_string 0x0123ABCD // hash of \u0026#34;some_other_string\u0026#34; usage in code\n#include \u0026#34;my_hashes.hash.h\u0026#34; void my_func( uint32_t val ) { switch( val ) { case HASH_some_string: do_some_stuff(); break; case HASH_some_other_string: do_some_other_stuff(); break; } } With a resonable buildsystem in place this can be automated and never be in your way. I have it setup to collect all \u0026lt;filename\u0026gt;.hash-files and output \u0026lt;filename\u0026gt;.hash.h.\nSo lets compare the different solutions and see why I prefer the one I do by just listing my perceived pros/cons.\nThe biggest pro for using the c++-compiler itself for this is to not need a custom buildstep for the hashes and that is a really fair point. No need to setup a buildsystem or manually generate the headers can really be an important point in some cases, especially when distributing code to others. Also having the hashed string where it is used is by some considered a pro, for me it is a + but a small one. But that is about where the pros stop i.m.h.o.\nOn the cons list I think the biggest 2 are that I have to trust the compiler to do the right thing and paying the cost for generating this each time I compile my code.\nLet\u0026rsquo;s start of with the first one, trusting the compiler. Sure, compilers are smart etc but are we sure that the compiler will optimize a HashOfString(\u0026quot;some_string) to a constant? If it does with your current compiler, will it with another compiler? What happens when a new version of your compiler is released? With the simple \u0026ldquo;generate a .h\u0026rdquo;-file I am quite sure that it will evaluate to a constant and I will not have to think about it.\nThe other issue with compile-time hashes in pure c++ is why pay for something all the time when you can pay for it once? I.e. if I put code in a .cpp to generate a hash by the compiler it will cost time each time I compile that file. When generating a header I pay for it once, when I change the text-file with the strings to hash.\nWe also have some other pros that are not as big, but I might just as well list them here for completeness:\neasier to find the actual value of the hash. When generating a header you just look in the header, when doing it with the compiler\u0026hellip; it gets harder! you have control over how the header is generated, you want to add registering of hash-value -\u0026gt; string? just add it! So what do you think, what pros have I missed on hashing with the c++-compiler? Why am I wrong?\n"
            }
    
        ,
            {
                "id": 11,
                "href": "http://kihlander.net/post/command-line-args-as-config/",
                "title": "The command-line as a poor mans config files",
                "section": "post",
                "date" : "2016.03.01",
                "body": "I like command-line arguments as mentioned in an earlier post about them. In this post I\u0026rsquo;ll discuss a method to use them as simple config-files.\nLet\u0026rsquo;s start of with a usage example from my own code. I have a meshviewer/particleviewer that is used for, you guessed it, viewing meshes and particle-effects. These kind of resources, at least the particle-effects, have internal paths to resources that need to be read while loading ( particles have a material to be rendered with etc ), i.e. resources from \u0026ldquo;some game\u0026rdquo; need to be found by the particle-viewer. Since reading resources is done via a VFS ( Virtual File System ) and paths is always specified via this VFS in resources we must just make sure that \u0026ldquo;some game\u0026rdquo;:s resources is mounted in the particle-viewer!\nLuckily for me this can be done via, you guessed it, the command line!\n./meshviewer --vfs-mount-uri=file:///path/to/assets --vfs-mount-point=/assets/ /assets/mesh/mesh_in_game_to_view.mesh Nice! But writing out this when you want to just test a resource from one project might be hard to remember and a bit of a hassle =/ So lets add one more command-line switch, --cmd-file=\u0026lt;path_to_file\u0026gt;! What this simply does is read the pointed to file, split it at white-space, add it to argc/argv. TADA! simple config-files done + all that can be configurate via files can also be configurated via the command-line.\nIf we let --cmd-file=\u0026lt;path_to_file\u0026gt; be recursive, we can do sub-files as well.\nThe above then becomes:\n./meshviewer --cmd-file=setup_some_game.cmd /assets/mesh/mesh_in_game_to_view.mesh In this specific case it might not save you that much, but consider you having multiple games, multiple configs etc.\nDo I think this would replace all configuration ever? Absolutely not, but it works great for small things as above. I would absolutely not do this for settings that should be used in a shipped game, only for debug-settings and other settings used during development.\nShort post, but hopefully someone like this and steal it :)\n"
            }
    
        ,
            {
                "id": 12,
                "href": "http://kihlander.net/post/registering-command-line-args/",
                "title": "Registering command line arguments",
                "section": "post",
                "date" : "2016.02.27",
                "body": "I really like using command line arguments. I think that it is a flexible way to interact with and configure my games/engine. It is for example easier to just add a --log-verbose=resource to set all logging in the \u0026ldquo;resource\u0026rdquo;-domain to verbose or --memory-enable-stacktrace=render to enable save of stacktraces for all allocations done in the \u0026ldquo;render\u0026rdquo;-allocator than to edit some config-file somewhere. At least for things such as the ones mentioned above, that is only set once in a while.\nNote: It\u0026rsquo;s also a simple replacement for config-files, but that is something for a later blog-post ;)\nHowever it seems like there\u0026rsquo;s always one problem, how to register supported command-line arguments to show \u0026ndash;help and check that arguments are correctly specified? In this blog-post I\u0026rsquo;ll outline a solution that I have found works really well for me. It has its drawbacks but that is usually the case with any solution to any problem ;)\nWhat do I want to achieve? Let\u0026rsquo;s make a quick list over what I want from my system.\nDifferent systems to be able to register their supported command line arguments in a simple fashion. Automatic \u0026ndash;help generation ( I always forget what flags are there etc, \u0026ndash;help to the rescue ) Systems that register args should be able to assume that all flags are valid when they get the args. How I do it First of all I let all systems parse their own argc/argv, in other words I just pass each system a reference to argc/argv. This is done in different ways, but usually something like this:\nlog_ctx_t logger = log_ctx_create( /*... some param ... */, argc, argv ); or this:\nrenderer_create_info create_info; // ... other params ... create_info.argc = argc; create_info.argv = argv; renderer_t r = renderer_create(\u0026amp;create_info); The systems get access to a const argc/argv and its their job to parse them by them self. For this I use ( shameless self-promotion comming up ) this getopt-parser https://github.com/wc-duck/getopt. But how does that tie in with our earlier demands on the \u0026ldquo;system\u0026rdquo;. Well, lets use some thing that some one consider the c++-equivalent of swearing in church, global constructors! Lets introduce a simple helper-class and macro GETOPT_ARGS_REGISTER().\nstruct __getopt_args_register { __getopt_args_register( const char* t, const getopt_option_t* opt ) : next( first ) , options_title( t ) , opts( opt ) { first = this; } static __getopt_args_register* first; __getopt_args_register* next; const char* options_title; const getopt_option_t* opts; }; #define GETOPT_ARGS_REGISTER( options_title, options ) \\ static __getopt_args_register JOIN_MACRO_TOKENS( __getopt_reg, __LINE__ )( options_title, options ) And we use this as follows\nstatic getopt_option_t options_list[] = { { \u0026#34;log-info\u0026#34;, 0x0, GETOPT_OPTION_TYPE_OPTIONAL, 0x0, \u0026#39;i\u0026#39;, \u0026#34;set log-level info, globally if no domain is specified.\u0026#34;, \u0026#34;DOMAIN\u0026#34; }, { \u0026#34;log-error\u0026#34;, 0x0, GETOPT_OPTION_TYPE_OPTIONAL, 0x0, \u0026#39;e\u0026#39;, \u0026#34;set log-level error, globally if no domain is specified.\u0026#34;, \u0026#34;DOMAIN\u0026#34; }, { \u0026#34;log-warning\u0026#34;, 0x0, GETOPT_OPTION_TYPE_OPTIONAL, 0x0, \u0026#39;w\u0026#39;, \u0026#34;set log-level warning, globally if no domain is specified\u0026#34;, \u0026#34;DOMAIN\u0026#34; }, { \u0026#34;log-verbose\u0026#34;, \u0026#39;v\u0026#39;, GETOPT_OPTION_TYPE_OPTIONAL, 0x0, \u0026#39;v\u0026#39;, \u0026#34;set log-level verbose, globally if no domain is specified\u0026#34;, \u0026#34;DOMAIN\u0026#34; }, { \u0026#34;log-callstack\u0026#34;, 0x0, GETOPT_OPTION_TYPE_OPTIONAL, 0x0, \u0026#39;c\u0026#39;, \u0026#34;log callstacks together with messages, globally if no domain is specified\u0026#34;, \u0026#34;DOMAIN\u0026#34; }, { \u0026#34;log-domains\u0026#34;, 0x0, GETOPT_OPTION_TYPE_NO_ARG, 0x0, \u0026#39;d\u0026#39;, \u0026#34;log all available domains as they are discovered.\u0026#34; }, GETOPT_OPTIONS_END }; GETOPT_ARGS_REGISTER( \u0026#34;log\u0026#34;, options_list ); What the above macro basically does is on old trick, building an global linked list of __getopt_args_register when running global constructors that can be accessed via __getopt_args_register::first.\nWhen we have this info it is an easy thing to just loop over all registered args and do the error checking and \u0026ndash;help generation etc without the systems having to know about it. I usually do this as a really early part of int main( int argc, const char** argv ). Also notice that the registered options is the same type that is used by the getopt-library so that the same setup can be used during arg-parse. Keeping the registered args defined in one place and one place only.\nOne of the things I like most with this is that the registering is done link-time, so linking to a static library, in my case render, debug or vfs ( to mention a few ) auto-registers its options. So if a lib is not used/linked, no options is registered.\nDrawbacks Well there are some of course. This will not work well together will DLL:s since the main .exe and the .dll:s will get their own instance of __getopt_args_register::first and the ones in the dll will not be accessible from the exe. It could be solved by \u0026ldquo;pulling out\u0026rdquo; __getopt_args_register::first from each DLL and manually \u0026ldquo;link\u0026rdquo; them together but that is not something I have done or have had any need for.\nAlso there is the problem of colliding flag-names and that is best solved by just not sharing flag-names, I prefix my flags by system. In some cases you might even want colliding flag-names where you have flags that should be used by multiple systems. Not sure if it is a good idea, but it is definitely something that can be done.\nConclusion This is a technique that has served me well for this purpose and the \u0026ldquo;global linked list created with global constructors\u0026rdquo; could be a useful tool in your toolbox when writing c++. It need to be used restrictively, but at least for this purpose it has not been any problems for me.\n"
            }
    
]
